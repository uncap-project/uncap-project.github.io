{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2957746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# === IMPORT STATEMENT ===\n",
    "# -----------------------------\n",
    "import os, yaml, base64, time, sys, math, numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c42e77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m SCENARIO_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2021_08_23_21_47_19\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# change scenario\u001b[39;00m\n\u001b[1;32m      9\u001b[0m SCENARIO_SET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m    \u001b[38;5;66;03m# change scenario sets\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m BASE \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[1;32m     12\u001b[0m LABEL_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ID_label/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSCENARIO_SET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSCENARIO_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/label.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m SEG_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/TEST_ADDITIONAL/nocomms-additional/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSCENARIO_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/instance_seg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# === PARAMETERS & DIRECTORIES ===\n",
    "# ---------------------------------\n",
    "\n",
    "OPENAI_API_KEY = \"YOUR_API_KEY\" # replace with your api key!!\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "SCENARIO_ID = \"2021_08_23_21_47_19\" # change scenario\n",
    "SCENARIO_SET = \"test\"    # change scenario sets\n",
    "\n",
    "BASE = os.path.dirname(os.path.abspath(__file__))\n",
    "LABEL_FILE = f\"{BASE}/ID_label/{SCENARIO_SET}/{SCENARIO_ID}/label.txt\"\n",
    "SEG_DIR = f\"{BASE}/TEST_ADDITIONAL/nocomms-additional/{SCENARIO_ID}/instance_seg\"\n",
    "FRONT_DIR = f\"{BASE}/{SCENARIO_SET}/{SCENARIO_ID}\"\n",
    "FOV_DIR = f\"{BASE}/FOV_test/{SCENARIO_ID}\"\n",
    "\n",
    "YOLO_WEIGHTS = \"yolov9c.pt\"\n",
    "YOLO_CLASSES = {2, 7}        # car, truck\n",
    "PIXEL_THRESHOLD = 0          # min pixels for a valid vehicle\n",
    "IOU_THRESHOLD = 0.0          # IoU for matching YOLO and segmentation boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816485fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# === HELPER FUNCTIONS ===\n",
    "# -----------------------------\n",
    "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def color_to_id(c): r,g,b = c; return r + (g<<8) + (b<<16)\n",
    "\n",
    "def load_id_map(f):\n",
    "    id_map = {}\n",
    "    for line in open(f):\n",
    "        if line.strip():\n",
    "            carla, unreal = map(int, line.split())\n",
    "            id_map[unreal] = carla\n",
    "    return id_map\n",
    "\n",
    "def list_nums(path, ext):\n",
    "    return sorted(int(os.path.splitext(f)[0])\n",
    "                  for f in os.listdir(path) if f.endswith(ext) and os.path.splitext(f)[0].isdigit())\n",
    "\n",
    "def map_index(i, total, arr):\n",
    "    if not arr: return None\n",
    "    if total <= 1: return arr[0]\n",
    "    j = int(round(i * (len(arr)-1) / (total-1)))\n",
    "    return arr[max(0, min(j, len(arr)-1))]\n",
    "\n",
    "def iou(a,b):\n",
    "    xA,yA,xB,yB = max(a[0],b[0]), max(a[1],b[1]), min(a[2],b[2]), min(a[3],b[3])\n",
    "    inter = max(0,xB-xA)*max(0,yB-yA)\n",
    "    return inter / ( (a[2]-a[0])*(a[3]-a[1]) + (b[2]-b[0])*(b[3]-b[1]) - inter + 1e-6 )\n",
    "\n",
    "def get_bbox(np_img, color):\n",
    "    mask = np.all(np_img == color, axis=-1)\n",
    "    if not np.any(mask): return None\n",
    "    ys, xs = np.where(mask)\n",
    "    return [int(xs.min()), int(ys.min()), int(xs.max()), int(ys.max())]\n",
    "\n",
    "def greedy_match(seen, yolos):\n",
    "    \"\"\"Assign YOLO confidences to segmentation boxes via greedy lock-in by pixel area.\"\"\"\n",
    "    cids, confs, used = list(seen.keys()), {cid:0.0 for cid in seen}, set()\n",
    "    cands = {cid:[j for j,(b,_) in enumerate(yolos) if iou(seen[cid]['bbox'],b)>=IOU_THRESHOLD] for cid in cids}\n",
    "    while True:\n",
    "        wants = {}\n",
    "        for cid in cids:\n",
    "            prefs = [j for j in cands[cid] if j not in used]\n",
    "            if prefs: wants.setdefault(prefs[0], []).append(cid)\n",
    "        if not wants: break\n",
    "        for yidx, cid_list in wants.items():\n",
    "            win = max(cid_list, key=lambda c: seen[c]['pixels'])\n",
    "            confs[win] = float(yolos[yidx][1]); used.add(yidx)\n",
    "    return confs\n",
    "\n",
    "def list_yaml_ticks(cav_front_dir):\n",
    "    \"\"\"Return sorted tick numbers from FRONT_DIR per CAV (accepts plain or yaml/ subdir).\"\"\"\n",
    "    paths = [cav_front_dir, os.path.join(cav_front_dir, \"yaml\")]\n",
    "    ticks = set()\n",
    "    for p in paths:\n",
    "        if not os.path.isdir(p): continue\n",
    "        for fn in os.listdir(p):\n",
    "            base, ext = os.path.splitext(fn)\n",
    "            if ext.lower() == \".yaml\" and base.isdigit():\n",
    "                ticks.add(int(base))\n",
    "    return sorted(ticks)\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# === STAGE 1: Extract visible IDs ===\n",
    "# -------------------------------------\n",
    "def stage1_extract_visible_ids():\n",
    "    ids_map = load_id_map(LABEL_FILE)\n",
    "    ensure_dir(FOV_DIR)\n",
    "\n",
    "    cavs = [c for c in sorted(os.listdir(SEG_DIR)) if os.path.isdir(os.path.join(SEG_DIR, c))]\n",
    "    for cav in cavs:\n",
    "        seg_cav_dir   = os.path.join(SEG_DIR,   cav)\n",
    "        front_cav_dir = os.path.join(FRONT_DIR, cav)\n",
    "        save_dir      = os.path.join(FOV_DIR,   cav)\n",
    "        ensure_dir(save_dir)\n",
    "\n",
    "        # discover available frames\n",
    "        png_numbers = list_nums(seg_cav_dir, \".png\")              \n",
    "        ticks       = list_yaml_ticks(front_cav_dir)            \n",
    "        if not png_numbers or not ticks:\n",
    "            print(f\"[Stage1] CAV {cav}: no pngs ({len(png_numbers)}) or no ticks ({len(ticks)}). Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[Stage1] CAV {cav}: ticks={ticks[0]}..{ticks[-1]} ({len(ticks)}) | pngs={png_numbers[0]}..{png_numbers[-1]} ({len(png_numbers)})\")\n",
    "\n",
    "        last_seen = set()\n",
    "        for i, tick in enumerate(ticks):\n",
    "            png_num = map_index(i, len(ticks), png_numbers)   \n",
    "            img_path = os.path.join(seg_cav_dir, f\"{png_num:06}.png\")\n",
    "\n",
    "            visible_ids = set()\n",
    "            if os.path.isfile(img_path):\n",
    "                np_img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "                colors, counts = np.unique(np_img.reshape(-1,3), axis=0, return_counts=True)\n",
    "\n",
    "                for c, cnt in zip(colors, counts):\n",
    "                    if tuple(c) == (0,0,0) or cnt < PIXEL_THRESHOLD: \n",
    "                        continue\n",
    "                    uid = color_to_id(tuple(c))\n",
    "                    if uid in ids_map:\n",
    "                        visible_ids.add(ids_map[uid])\n",
    "\n",
    "            last_seen = visible_ids or last_seen\n",
    "            out_path = os.path.join(save_dir, f\"{tick}.txt\")\n",
    "            with open(out_path, \"w\") as f:\n",
    "                for vid in sorted(last_seen):\n",
    "                    f.write(f\"{vid}\\n\")\n",
    "\n",
    "        print(f\"[Stage1] CAV {cav}: wrote {len(ticks)} tick files to {save_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671069fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# === STAGE 2: Filter YAMLs ===\n",
    "# -----------------------------\n",
    "def stage2_filter_yamls(debug=True):\n",
    "    for cav in sorted(os.listdir(FOV_DIR)):\n",
    "        cav_dir = os.path.join(FOV_DIR, cav)\n",
    "        if not os.path.isdir(cav_dir):\n",
    "            continue\n",
    "\n",
    "        yaml_out = os.path.join(cav_dir, \"yaml\")\n",
    "        ensure_dir(yaml_out)\n",
    "\n",
    "        txts = sorted(f for f in os.listdir(cav_dir) if f.endswith(\".txt\"))\n",
    "        if debug:\n",
    "            print(f\"[Stage2] CAV={cav} txt_count={len(txts)} out={yaml_out}\")\n",
    "\n",
    "        wrote = 0\n",
    "        for txt in txts:\n",
    "            tick = os.path.splitext(txt)[0]\n",
    "            try:\n",
    "                tick_int = int(tick)\n",
    "            except:\n",
    "                if debug:\n",
    "                    print(f\"  [skip] non-numeric tick filename: {txt}\")\n",
    "                continue\n",
    "            tick_pad = f\"{tick_int:06d}\"\n",
    "            txt_path = os.path.join(cav_dir, txt)\n",
    "\n",
    "            # Try multiple YAML search paths and filename forms\n",
    "            candidates = [\n",
    "                os.path.join(FRONT_DIR, cav, f\"{tick}.yaml\"),\n",
    "                os.path.join(FRONT_DIR, cav, f\"{tick_pad}.yaml\"),\n",
    "                os.path.join(FRONT_DIR, cav, \"yaml\", f\"{tick}.yaml\"),\n",
    "                os.path.join(FRONT_DIR, cav, \"yaml\", f\"{tick_pad}.yaml\"),\n",
    "                os.path.join(FRONT_DIR, cav, f\"{tick}.yml\"),\n",
    "                os.path.join(FRONT_DIR, cav, f\"{tick_pad}.yml\"),\n",
    "                os.path.join(FRONT_DIR, cav, \"yaml\", f\"{tick}.yml\"),\n",
    "                os.path.join(FRONT_DIR, cav, \"yaml\", f\"{tick_pad}.yml\"),\n",
    "            ]\n",
    "            y_in = next((p for p in candidates if os.path.isfile(p)), None)\n",
    "            if not y_in:\n",
    "                if debug:\n",
    "                    print(f\"  [miss] tick={tick} (no YAML found)\")\n",
    "                continue\n",
    "\n",
    "            # --- Read visible IDs from txt file ---\n",
    "            with open(txt_path) as f:\n",
    "                visible_raw = [ln.strip().strip(\"'\\\"\") for ln in f if ln.strip()]\n",
    "\n",
    "            # Normalize visible IDs to integer-based strings\n",
    "            visible = set()\n",
    "            for v in visible_raw:\n",
    "                try:\n",
    "                    visible.add(str(int(v)))   # normalize e.g. \"003\" -> \"3\"\n",
    "                except:\n",
    "                    visible.add(v)\n",
    "\n",
    "            # --- Load YAML and filter vehicles ---\n",
    "            try:\n",
    "                with open(y_in) as f:\n",
    "                    y = yaml.safe_load(f) or {}\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(f\"  [err] Failed to read {y_in}: {e}\")\n",
    "                continue\n",
    "\n",
    "            vehicles_all = y.get(\"vehicles\", {}) or {}\n",
    "\n",
    "            # Normalize YAML keys as well for matching\n",
    "            filtered = {}\n",
    "            for k, v in vehicles_all.items():\n",
    "                try:\n",
    "                    norm_key = str(int(k))\n",
    "                except:\n",
    "                    norm_key = k\n",
    "                if norm_key in visible or k in visible:\n",
    "                    filtered[k] = v\n",
    "\n",
    "            y[\"vehicles\"] = filtered\n",
    "            out_path = os.path.join(yaml_out, f\"{tick_pad}.yaml\")\n",
    "            with open(out_path, \"w\") as f:\n",
    "                yaml.safe_dump(y, f, sort_keys=False)\n",
    "\n",
    "            wrote += 1\n",
    "            if debug:\n",
    "                print(f\"  [ok] tick={tick} -> {os.path.basename(out_path)}  \"\n",
    "                      f\"visible={len(visible)} matched={len(filtered)}\")\n",
    "\n",
    "        print(f\"[Stage2] CAV {cav}: wrote {wrote} filtered YAMLs.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# === STAGE 3: Add YOLO Confidences ===\n",
    "# -----------------------------\n",
    "\n",
    "def stage3_add_confidences(debug=True, debug_images=False):\n",
    "    ids_map = load_id_map(LABEL_FILE)\n",
    "    yolo = YOLO(YOLO_WEIGHTS)\n",
    "\n",
    "    for cav in sorted(os.listdir(FOV_DIR)):\n",
    "        cav_dir = os.path.join(FOV_DIR, cav)\n",
    "        y_dir = os.path.join(cav_dir, \"yaml\")\n",
    "        if not os.path.isdir(y_dir):\n",
    "            continue\n",
    "\n",
    "        seg_dir = os.path.join(SEG_DIR, cav)\n",
    "        ticks, pngs = list_nums(y_dir, \".yaml\"), list_nums(seg_dir, \".png\")\n",
    "        if not ticks or not pngs:\n",
    "            print(f\"[Stage3] Skipping {cav}: missing yaml or seg data.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[Stage3] CAV {cav}: {len(ticks)} YAMLs, {len(pngs)} seg frames.\")\n",
    "        out_vis = os.path.join(FOV_DIR, cav, \"vis\")\n",
    "        if debug_images:\n",
    "            ensure_dir(out_vis)\n",
    "\n",
    "        for i, t in enumerate(ticks):\n",
    "            seg_num = map_index(i, len(ticks), pngs)\n",
    "            seg_path = os.path.join(seg_dir, f\"{seg_num:06}.png\")\n",
    "            front_path = os.path.join(FRONT_DIR, cav, f\"{t:06}_camera0.png\")\n",
    "            yaml_path = os.path.join(y_dir, f\"{t:06}.yaml\")\n",
    "            if not os.path.isfile(yaml_path):\n",
    "                continue\n",
    "\n",
    "            # --- collect segmentation boxes ---\n",
    "            seen = {}\n",
    "            if os.path.isfile(seg_path):\n",
    "                np_img = np.array(Image.open(seg_path).convert(\"RGB\"))\n",
    "                colors, counts = np.unique(np_img.reshape(-1, 3), axis=0, return_counts=True)\n",
    "                for c, cnt in zip(colors, counts):\n",
    "                    if tuple(c) == (0, 0, 0) or cnt < PIXEL_THRESHOLD:\n",
    "                        continue\n",
    "                    uid = color_to_id(tuple(c))\n",
    "                    if uid not in ids_map:\n",
    "                        continue\n",
    "                    cid = ids_map[uid]\n",
    "                    bbox = get_bbox(np_img, tuple(c))\n",
    "                    if bbox:\n",
    "                        seen[str(cid)] = {\"bbox\": bbox, \"pixels\": cnt, \"conf\": 0.0}\n",
    "\n",
    "            # --- YOLO detections ---\n",
    "            yolo_boxes = []\n",
    "            if os.path.isfile(front_path):\n",
    "                res = yolo(front_path, verbose=False)[0]\n",
    "                for b in res.boxes:\n",
    "                    if int(b.cls) in YOLO_CLASSES:\n",
    "                        yolo_boxes.append((b.xyxy.cpu().numpy().flatten().tolist(), float(b.conf)))\n",
    "\n",
    "            # --- IoU matching ---\n",
    "            matched_conf = {}\n",
    "            for cid, seg in seen.items():\n",
    "                best_conf = 0.0\n",
    "                for yb, conf in yolo_boxes:\n",
    "                    if iou(seg[\"bbox\"], yb) >= IOU_THRESHOLD:\n",
    "                        best_conf = max(best_conf, conf)\n",
    "                matched_conf[cid] = best_conf\n",
    "                seen[cid][\"conf\"] = best_conf\n",
    "\n",
    "            # --- update YAML ---\n",
    "            with open(yaml_path) as f:\n",
    "                y = yaml.safe_load(f) or {}\n",
    "            vehicles = y.get(\"vehicles\", {})\n",
    "            matched = 0\n",
    "            for k, v in vehicles.items():\n",
    "                norm_k = str(int(k))\n",
    "                if norm_k in matched_conf:\n",
    "                    v[\"confidence\"] = float(matched_conf[norm_k])\n",
    "                    matched += 1\n",
    "            y[\"vehicles\"] = vehicles\n",
    "            with open(yaml_path, \"w\") as f:\n",
    "                yaml.safe_dump(y, f, sort_keys=False)\n",
    "\n",
    "            # --- optional visualization ---\n",
    "            if debug_images and os.path.isfile(seg_path) and os.path.isfile(front_path):\n",
    "                seg_img = Image.open(seg_path).convert(\"RGB\")\n",
    "                front_img = Image.open(front_path).convert(\"RGB\")\n",
    "                draw_seg = ImageDraw.Draw(seg_img)\n",
    "                for cid, info in seen.items():\n",
    "                    draw_seg.rectangle(info[\"bbox\"], outline=\"blue\", width=2)\n",
    "                    draw_seg.text((info[\"bbox\"][0], info[\"bbox\"][1]), f\"{cid}\", fill=\"blue\")\n",
    "                draw_front = ImageDraw.Draw(front_img)\n",
    "                for b, conf in yolo_boxes:\n",
    "                    draw_front.rectangle(b, outline=\"red\", width=2)\n",
    "                    draw_front.text((b[0], b[1]), f\"{conf:.2f}\", fill=\"red\")\n",
    "                seg_img.save(os.path.join(out_vis, f\"{t:06}_seg.png\"))\n",
    "                front_img.save(os.path.join(out_vis, f\"{t:06}_yolo.png\"))\n",
    "\n",
    "            if debug:\n",
    "                print(f\"  [tick {t}] seg={len(seen)} yolo={len(yolo_boxes)} matched={matched}\")\n",
    "\n",
    "        print(f\"[Stage3] CAV {cav} confidence updated.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e161527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------\n",
    "# === EXECUTION EXTRACTING FOV INFO ===\n",
    "# --------------------------------------\n",
    "stage1_extract_visible_ids()\n",
    "stage2_filter_yamls()\n",
    "stage3_add_confidences()\n",
    "print(\"All stages complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# === STAGE 4: Generate Structured Format via Combined Data ===\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "SCENARIO_ID = \"2021_08_23_21_47_19\" # change scenario\n",
    "SCENARIO_SET = \"test\"    # change scenario sets\n",
    "EVAL_CAV_ID = \"243\"\n",
    "HELPER_CAV_ID = \"234\"\n",
    "EVAL_INTENTION = \"would like to move north\"\n",
    "EVAL_FACING = \"north\"\n",
    "\n",
    "\n",
    "BASE = os.path.dirname(os.path.abspath(__file__))\n",
    "LABEL_FILE = f\"{BASE}/ID_label/{SCENARIO_SET}/{SCENARIO_ID}/label.txt\"\n",
    "SEG_DIR = f\"{BASE}/TEST_ADDITIONAL/nocomms-additional/{SCENARIO_ID}/instance_seg\"\n",
    "FRONT_DIR = f\"{BASE}/{SCENARIO_SET}/{SCENARIO_ID}\"\n",
    "FOV_DIR = f\"{BASE}/FOV_test/{SCENARIO_ID}\"\n",
    "\n",
    "COMBINED_BEV_DIR = f\"{BASE}/combined_data/bevs/{SCENARIO_ID}/\"\n",
    "COMBINED_YAML_DIR = f\"{BASE}/combined_data/yamls/{SCENARIO_ID}/\"\n",
    "STRUCTURED_FORMAT_DIR = f\"{BASE}/structured_format/{SCENARIO_ID}/\"\n",
    "HELPER_SEEN_DIR = f\"{FOV_DIR}/\"\n",
    "\n",
    "\n",
    "Scene 2\n",
    "\n",
    "def stage4_generate_structured_format():\n",
    "    print(f\">>> BEGINNING EVAL ON {SCENE_TO_USE}\")\n",
    "\n",
    "    root_data_dir = \"../FOV_vehicles/2021_08_23_21_47_19/\"\n",
    "    eval_view_dir = \"../test/2021_08_23_21_47_19/243/\"\n",
    "    helper_cav_id = \"234\"\n",
    "    eval_cav_id = \"243\"\n",
    "    helper_seen_dir = \"../FOV_vehicles/2021_08_23_21_47_19/234/\"\n",
    "    eval_seen_dir = \"../FOV_vehicles/2021_08_23_21_47_19/243/\"\n",
    "    eval_intention = \"would like to move north\"\n",
    "    eval_facing = \"north\"\n",
    "    # outputs\n",
    "    out_dir = f\"./scene_2_structured_format/\"\n",
    "    bev_path_dir = f\"./scene_2_data/bevs/\"\n",
    "    yaml_path_dir = f\"./scene_2_data/yamls/\"\n",
    "    elif (SCENE_TO_USE == 3):\n",
    "        root_data_dir = \"../FOV_vehicles/2021_08_23_15_19_19/\"\n",
    "        eval_view_dir = \"../test/2021_08_23_15_19_19/8690/\"\n",
    "        helper_cav_id = \"8699\"\n",
    "        eval_cav_id = \"8690\"\n",
    "        helper_seen_dir = \"../FOV_vehicles/2021_08_23_15_19_19/8699\"\n",
    "        eval_seen_dir = \"../FOV_vehicles/2021_08_23_15_19_19/8690\"\n",
    "        eval_intention = \"would like to move west\"\n",
    "        eval_facing = \"west\"\n",
    "        # outputs\n",
    "        out_dir = f\"./scene_3_structured_format/\"\n",
    "        bev_path_dir = f\"./scene_3_data/bevs/\"\n",
    "        yaml_path_dir = f\"./scene_3_data/yamls/\"\n",
    "    elif (SCENE_TO_USE == 4):\n",
    "        root_data_dir = \"../FOV_vehicles/2021_08_20_21_10_24_original/\"\n",
    "        eval_view_dir = \"../test/2021_08_20_21_10_24/1996/\"\n",
    "        helper_cav_id = \"2014\"\n",
    "        eval_cav_id = \"1996\"\n",
    "        helper_seen_dir = \"../FOV_vehicles/2021_08_20_21_10_24_original/2014\"\n",
    "        eval_seen_dir = \"../FOV_vehicles/2021_08_20_21_10_24_original/1996\"\n",
    "        eval_intention = \"would like to merge into the lane to its right (the one directly North) once it is on the highway\"\n",
    "        eval_facing = \"west\" # note: should not be used!\n",
    "        # outputs\n",
    "        out_dir = f\"./scene_4_structured_format/\"\n",
    "        bev_path_dir = f\"./scene_4_data/bevs/\"\n",
    "        yaml_path_dir = f\"./scene_4_data/yamls/\"\n",
    "    elif (SCENE_TO_USE == 5):\n",
    "        root_data_dir = \"../FOV_vehicles/2021_08_22_06_43_37/\"\n",
    "        eval_view_dir = \"../train/2021_08_22_06_43_37/3152/\"\n",
    "        helper_cav_id = \"3170\"\n",
    "        eval_cav_id = \"3152\"\n",
    "        helper_seen_dir = \"../FOV_vehicles/2021_08_22_06_43_37/3170\"\n",
    "        eval_seen_dir = \"../FOV_vehicles/2021_08_22_06_43_37/3152\"\n",
    "        eval_intention = \"would like to move north\"\n",
    "        eval_facing = \"north\"\n",
    "        # outputs\n",
    "        out_dir = f\"./scene_5_structured_format/\"\n",
    "        bev_path_dir = f\"./scene_5_data/bevs/\"\n",
    "        yaml_path_dir = f\"./scene_5_data/yamls/\"\n",
    "    elif (SCENE_TO_USE in [6, 7, 8, 9]):\n",
    "        if (SCENE_TO_USE == 6):\n",
    "            scene_param_str = \"2025_09_14_16_04_20\"\n",
    "            eval_intention = \"would like to turn south\"\n",
    "            eval_facing = \"west\"\n",
    "        elif (SCENE_TO_USE == 7):\n",
    "            scene_param_str = \"2025_09_14_16_23_41\"\n",
    "            eval_intention = \"would like to move west\"\n",
    "            eval_facing = \"west\"\n",
    "        elif (SCENE_TO_USE == 8):\n",
    "            scene_param_str = \"2025_10_07_01_09_57\"\n",
    "            eval_intention = \"would like to move south\"\n",
    "            eval_facing = \"south\"\n",
    "        elif (SCENE_TO_USE == 9):\n",
    "            scene_param_str = \"2025_10_07_01_13_20\"\n",
    "            eval_intention = \"would like to turn south\"\n",
    "            eval_facing = \"east\"\n",
    "        else:\n",
    "            print(\"INVALID SCENE NUMBER!!\")\n",
    "            sys.exit()\n",
    "\n",
    "        root_data_dir = f\"../FOV_vehicles/{scene_param_str}/\"\n",
    "        if (SCENE_TO_USE == 7):\n",
    "            eval_view_dir = f\"../custom_scenario/{scene_param_str}/002/rgb/front/\"\n",
    "            helper_cav_id = \"001\"\n",
    "            eval_cav_id = \"002\"\n",
    "        else:\n",
    "            eval_view_dir = f\"../custom_scenario/{scene_param_str}/001/rgb/front/\"\n",
    "            helper_cav_id = \"002\"\n",
    "            eval_cav_id = \"001\"\n",
    "\n",
    "        helper_seen_dir = root_data_dir + helper_cav_id\n",
    "        eval_seen_dir = root_data_dir + eval_cav_id\n",
    "        # outputs\n",
    "        out_dir = f\"./scene_{SCENE_TO_USE}_structured_format/\"\n",
    "        bev_path_dir = f\"./scene_{SCENE_TO_USE}_data/bevs/\"\n",
    "        yaml_path_dir = f\"./scene_{SCENE_TO_USE}_data/yamls/\"\n",
    "\n",
    "    else:\n",
    "        print(\"BAD SCENE INDEX!!!\")\n",
    "\n",
    "    def test_eval_with_prompt(prompt_str, timestamp):\n",
    "        if (SCENE_TO_USE in [4.5, 6, 7, 8, 9]):\n",
    "            base64_image_eval = encode_image(eval_view_dir + str(timestamp).zfill(6) + \".png\")\n",
    "        else:\n",
    "            base64_image_eval = encode_image(eval_view_dir + str(timestamp).zfill(6) + \"_camera0.png\")\n",
    "        if (SCENE_TO_USE in [1, 2, 3]):\n",
    "            base64_image_bev = encode_image(bev_path_dir + str(timestamp) + \".png\")\n",
    "        else:\n",
    "            base64_image_bev = encode_image(bev_path_dir + str(timestamp).zfill(6) + \".png\")\n",
    "        start_time = time.time()\n",
    "    \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt_str},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image_bev}\",\n",
    "                            },\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image_eval}\",\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            seed=42,\n",
    "            temperature=0.0000001\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        return({\"time_taken\": end_time-start_time, \"response\": response.choices[0].message.content})\n",
    "\n",
    "    # generate combined yamls and bevs for each timestamp (RUN AGAIN EACH RESTART)\n",
    "\n",
    "    import os\n",
    "    import yaml\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Rectangle as rec\n",
    "    from matplotlib.transforms import Affine2D\n",
    "\n",
    "    # BEV Gen\n",
    "\n",
    "    bev_gen_out_dir = bev_path_dir\n",
    "    yaml_gen_out_dir = yaml_path_dir\n",
    "    FOV_ROOT = root_data_dir\n",
    "\n",
    "    def ensure_dir(path):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    cav_ids = [eval_cav_id, helper_cav_id] # EVAL IS 0\n",
    "\n",
    "    yaml_dir_0 = os.path.join(FOV_ROOT, str(cav_ids[0]), \"yaml\")\n",
    "    yaml_dir_1 = os.path.join(FOV_ROOT, str(cav_ids[1]), \"yaml\")\n",
    "    ensure_dir(bev_gen_out_dir)\n",
    "    ensure_dir(yaml_gen_out_dir)\n",
    "    ensure_dir(yaml_dir_0)\n",
    "    ensure_dir(yaml_dir_1)\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    ticks = sorted([f.replace(\".yaml\", \"\") for f in os.listdir(yaml_dir_0) if f.endswith(\".yaml\")])\n",
    "\n",
    "    with open(os.path.join(yaml_dir_0, f\"{ticks[0]}.yaml\")) as f:\n",
    "        data_0 = yaml.safe_load(f)\n",
    "\n",
    "    with open(os.path.join(yaml_dir_1, f\"{ticks[0]}.yaml\")) as f:\n",
    "        data_1 = yaml.safe_load(f)\n",
    "\n",
    "    min_x, max_x = float('inf'), float('-inf')\n",
    "    min_y, max_y = float('inf'), float('-inf')\n",
    "\n",
    "    x, y = data_0[\"true_ego_pos\"][:2]\n",
    "    x = -x\n",
    "    min_x = min(min_x, x)\n",
    "    max_x = max(max_x, x)\n",
    "    min_y = min(min_y, y)\n",
    "    max_y = max(max_y, y)\n",
    "\n",
    "    x, y = data_1[\"true_ego_pos\"][:2]\n",
    "    x = -x\n",
    "    min_x = min(min_x, x)\n",
    "    max_x = max(max_x, x)\n",
    "    min_y = min(min_y, y)\n",
    "    max_y = max(max_y, y)\n",
    "\n",
    "    for bg_info in data_0.get(\"vehicles\", {}).values():\n",
    "        bx, by = bg_info[\"location\"][:2]\n",
    "        bx = -bx\n",
    "        min_x = min(min_x, bx)\n",
    "        max_x = max(max_x, bx)\n",
    "        min_y = min(min_y, by)\n",
    "        max_y = max(max_y, by)\n",
    "\n",
    "    for bg_info in data_1.get(\"vehicles\", {}).values():\n",
    "        bx, by = bg_info[\"location\"][:2]\n",
    "        bx = -bx\n",
    "        min_x = min(min_x, bx)\n",
    "        max_x = max(max_x, bx)\n",
    "        min_y = min(min_y, by)\n",
    "        max_y = max(max_y, by)\n",
    "\n",
    "    padding = 30\n",
    "    min_x -= padding\n",
    "    max_x += padding\n",
    "    min_y -= padding\n",
    "    max_y += padding\n",
    "\n",
    "    if (SCENE_TO_USE == 1):\n",
    "        min_x = min(min_x, 230)\n",
    "    elif (SCENE_TO_USE == 2):\n",
    "        min_x = min(min_x, 30)\n",
    "        max_y = max(max_y, 30)\n",
    "    elif (SCENE_TO_USE in [4, 4.5]):\n",
    "        min_x -= 100\n",
    "        min_y += 20\n",
    "        max_y -= 20\n",
    "\n",
    "    for tick in ticks:\n",
    "        yaml_path_0 = os.path.join(yaml_dir_0, f\"{tick}.yaml\")\n",
    "        with open(yaml_path_0) as f:\n",
    "            data_0 = yaml.safe_load(f)\n",
    "\n",
    "        yaml_path_1 = os.path.join(yaml_dir_1, f\"{tick}.yaml\")\n",
    "        with open(yaml_path_1) as f:\n",
    "            data_1 = yaml.safe_load(f)\n",
    "\n",
    "        combined_vehicle_dict = {**data_0.get(\"vehicles\", {}), **data_1.get(\"vehicles\", {})}\n",
    "\n",
    "        combined_yaml = {\n",
    "            \"true_ego_pos\": data_0.get(\"true_ego_pos\", []),\n",
    "            \"ego_speed\": data_0.get(\"ego_speed\", -1.0),\n",
    "            \"true_helper_pos\": data_1.get(\"true_ego_pos\", []),\n",
    "            \"helper_speed\": data_1.get(\"ego_speed\", -1.0),\n",
    "            \"vehicles\": {\n",
    "                str(vid): info for vid, info in combined_vehicle_dict.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        combined_yaml_out_path = os.path.join(yaml_gen_out_dir, f\"{tick}.yaml\")\n",
    "        with open(combined_yaml_out_path, \"w\") as f:\n",
    "            yaml.dump(combined_yaml, f)\n",
    "        if (int(tick) % 3 == 0):\n",
    "            print(f\"[Saved] {combined_yaml_out_path}\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "        helper_drawn_as_seen = False\n",
    "\n",
    "        # Plot ego A\n",
    "        x, y = data_0[\"true_ego_pos\"][:2]\n",
    "        x = -x\n",
    "        yaw = -np.deg2rad(data_0[\"true_ego_pos\"][4])\n",
    "        tform = Affine2D().rotate_around(x, y, yaw)\n",
    "        rect = rec((x - 2.25, y - 1), 4.5, 2, facecolor='pink', edgecolor='pink', transform=tform + ax.transData)\n",
    "        ax.add_patch(rect)\n",
    "        ax.plot([x, x + 2 * np.cos(yaw)], [y, y + 2 * np.sin(yaw)], color='pink')\n",
    "        ax.text(x, y, cav_ids[0], ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "        # Plot ego B\n",
    "        x, y = data_1[\"true_ego_pos\"][:2]\n",
    "        x = -x\n",
    "        yaw = -np.deg2rad(data_1[\"true_ego_pos\"][4])\n",
    "        tform = Affine2D().rotate_around(x, y, yaw)\n",
    "        rect = rec((x - 2.25, y - 1), 4.5, 2, facecolor='pink', edgecolor='pink', transform=tform + ax.transData)\n",
    "        ax.add_patch(rect)\n",
    "        ax.plot([x, x + 2 * np.cos(yaw)], [y, y + 2 * np.sin(yaw)], color='pink')\n",
    "        ax.text(x, y, cav_ids[1], ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "        # Plot background vehicles\n",
    "        dict_0 = data_0.get(\"vehicles\", {})\n",
    "        for bg_id, bg_info in dict_0.items():\n",
    "            if (str(bg_id) in cav_ids):\n",
    "                continue\n",
    "\n",
    "            x, y = bg_info[\"location\"][:2]\n",
    "            x = -x\n",
    "            yaw = -np.deg2rad(bg_info[\"angle\"][1])\n",
    "            tform = Affine2D().rotate_around(x, y, yaw)\n",
    "            rect = rec((x - 2.25, y - 1), 4.5, 2,\n",
    "                        facecolor='yellow', edgecolor='yellow', alpha=0.7,\n",
    "                        transform=tform + ax.transData)\n",
    "            ax.add_patch(rect)\n",
    "            ax.plot([x, x + 2 * np.cos(yaw)], [y, y + 2 * np.sin(yaw)], color='yellow')\n",
    "            ax.text(x, y, str(bg_id), ha='center', va='center', fontsize=12, color='black')\n",
    "        \n",
    "        dict_1 = data_1.get(\"vehicles\", {})\n",
    "        for bg_id, bg_info in dict_1.items():\n",
    "            if ((bg_id in dict_0) or (str(bg_id) in cav_ids)):\n",
    "                continue\n",
    "\n",
    "            x, y = bg_info[\"location\"][:2]\n",
    "            x = -x\n",
    "            yaw = -np.deg2rad(bg_info[\"angle\"][1])\n",
    "            tform = Affine2D().rotate_around(x, y, yaw)\n",
    "            rect = rec((x - 2.25, y - 1), 4.5, 2,\n",
    "                        facecolor='yellow', edgecolor='yellow', alpha=0.7,\n",
    "                        transform=tform + ax.transData)\n",
    "            ax.add_patch(rect)\n",
    "            ax.plot([x, x + 2 * np.cos(yaw)], [y, y + 2 * np.sin(yaw)], color='yellow')\n",
    "            ax.text(x, y, str(bg_id), ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "        ax.set_xlim(min_x, max_x)\n",
    "        ax.set_ylim(min_y, max_y)\n",
    "        ax.set_aspect('equal')\n",
    "        plt.title(f\"Tick {tick} | CAVs {cav_ids[0]} (EGO) and {cav_ids[1]} (HELPER)\")\n",
    "        plt.savefig(os.path.join(bev_gen_out_dir, f\"{tick}.png\"), dpi=300)\n",
    "        plt.close()\n",
    "        #if (int(tick) % 3 == 0):\n",
    "        #    print(f\"[Saved] {bev_gen_out_dir}/{tick}.png\")\n",
    "\n",
    "    print(\"> BEV and YAML generation complete.\")\n",
    "\n",
    "    import re\n",
    "    import yaml\n",
    "    import numpy as np\n",
    "\n",
    "    ticks.sort()\n",
    "\n",
    "    directions_global = ['E', 'ENE', 'NE', 'NNE', 'N', 'NNW', 'NW', 'WNW', 'W', 'WSW', 'W', 'SSW', 'S', 'SSE', 'SE', 'ESE']\n",
    "\n",
    "    all_times_taken_sum = 0.0\n",
    "    all_times_taken_num = 0\n",
    "\n",
    "    for tick in ticks:\n",
    "        if (int(tick) != 99 and SCENE_TO_USE == 1) or (int(tick) != 103 and SCENE_TO_USE == 2):\n",
    "            continue\n",
    "        print(f\"Beginning eval for tick {tick}...\", end=\"\")\n",
    "        if (SCENE_TO_USE not in [4, 4.5]):\n",
    "            eval = test_eval_with_prompt(\n",
    "                f\"\"\"You are an AI assistant that helps with safe driving from a high-level perspective. \n",
    "                You are working with a scenario in which there are some autonomous cars and many regular cars. \n",
    "                You must refer to them by their IDs, which are used to label them. \n",
    "\n",
    "                You are provided with two images: \n",
    "                - a birds-eye view of an intersection with some autonomous cars and some regular cars; \n",
    "                - the front view of Vehicle {eval_cav_id}, called the Ego CAV. \n",
    "\n",
    "                In the birds-eye view, the autonomous cars are colored pink and the regular cars are colored yellow. \n",
    "                You must refer to them by their IDs, which are used to label them. \n",
    "                Directions on this map are given as you see them: North is up, South is down, East is right, West is left. \n",
    "\n",
    "                The vehicle of interest in this scenario is Vehicle {eval_cav_id}, called the Ego CAV. It currently {eval_intention}. It is currently facing {eval_facing}. \n",
    "\n",
    "                Your task is to discern which vehicles might interfere with the motion of the Ego CAV such that it should know about them in order to make a safe decision.\n",
    "                When including relevant vehicles, try to think forward in time and consider how the vehicles may interact over the next few seconds or whether their paths could potentially intersect.\n",
    "                At the end of your response, you must include a space-separated list of the vehicle IDs of interest in this EXACT format:\n",
    "\n",
    "                id_1 id_2 ... id_n\n",
    "\n",
    "                Or, only if there are no vehicle IDs of interest, include at the end of your response the number:\n",
    "\n",
    "                0\n",
    "                \n",
    "                \"\"\",\n",
    "                int(tick)\n",
    "            )\n",
    "        else:\n",
    "            eval = test_eval_with_prompt(\n",
    "                f\"\"\"You are an AI assistant that helps with safe driving from a high-level perspective. \n",
    "                You are working with a scenario in which there are some autonomous cars and many regular cars. \n",
    "                You must refer to them by their IDs, which are used to label them. \n",
    "\n",
    "                You are provided with two images: \n",
    "                - a birds-eye view of an intersection with some autonomous cars and some regular cars; \n",
    "                - the front view of Vehicle {eval_cav_id}, called the Ego CAV. \n",
    "\n",
    "                In the birds-eye view, the autonomous cars are colored pink and the regular cars are colored yellow. \n",
    "                You must refer to them by their IDs, which are used to label them. \n",
    "                Directions on this map are given as you see them: North is up, South is down, East is right, West is left. \n",
    "\n",
    "                The vehicle of interest in this scenario is Vehicle {eval_cav_id}, called the Ego CAV. It currently {eval_intention}. It either is merging or has recently merged onto the highway headed west. \n",
    "\n",
    "                Your task is to discern which vehicles might interfere with the motion of the Ego CAV such that it should know about them in order to make a safe decision.\n",
    "                At the end of your response, you must include a space-separated list of the vehicle IDs of interest in this EXACT format:\n",
    "\n",
    "                id_1 id_2 ... id_n\n",
    "\n",
    "                Or, only if there are no vehicle IDs of interest, include at the end of your response the number:\n",
    "\n",
    "                0\n",
    "                \n",
    "                \"\"\",\n",
    "                int(tick)\n",
    "            )\n",
    "        \n",
    "        print(\" done!\")\n",
    "\n",
    "        # NOTE:positions are given relative to ego's north; may misalign with bev in scene 2 since it turns\n",
    "        # (positions are still correct but may confuse vlm)\n",
    "\n",
    "        #print(\"Eval response:\\n\\n\" + eval['response'] + \"\\n-----------\\n\")\n",
    "\n",
    "        time_taken_this_tick = eval['time_taken']\n",
    "        all_times_taken_num += 1\n",
    "        all_times_taken_sum += time_taken_this_tick\n",
    "        nearby_list = eval['response']\n",
    "        nearby_list_lines = nearby_list.strip().splitlines()\n",
    "\n",
    "        def describe_relative_direction(ego_x, ego_y, ego_yaw, other_x, other_y, other_yaw):\n",
    "            directions = ['E', 'ENE', 'NE', 'NNE', 'N', 'NNW', 'NW', 'WNW', 'W', 'WSW', 'W', 'SSW', 'S', 'SSE', 'SE', 'ESE']\n",
    "            \n",
    "            dx = other_x - ego_x\n",
    "            dy = other_y - ego_y\n",
    "\n",
    "            distance_val = math.sqrt(dx*dx + dy*dy)\n",
    "            if (distance_val < 6):\n",
    "                distance = \"very close\"\n",
    "            elif (distance_val < 10):\n",
    "                distance = \"close\"\n",
    "            elif (distance_val < 15):\n",
    "                distance = \"somewhat far\"\n",
    "            else:\n",
    "                distance = \"far\"\n",
    "\n",
    "            relative_angle = math.atan2(dy,dx)\n",
    "            relative_angle += (math.pi/2 - ego_yaw)\n",
    "            relative_angle += math.pi # correction for sim data\n",
    "            if (relative_angle < 0):\n",
    "                relative_angle += 2*math.pi\n",
    "            \n",
    "            rel_dir = directions[int((relative_angle + math.pi/16) / (math.pi/8)) % 16]\n",
    "\n",
    "            relative_yaw = (math.pi/2 - ego_yaw) + other_yaw\n",
    "            if (relative_yaw < 0):\n",
    "                relative_yaw += 2 * math.pi\n",
    "\n",
    "            facing = directions[int((relative_yaw + math.pi/16)/(math.pi/8)) % 16]\n",
    "\n",
    "            return (rel_dir, distance_val, distance, facing)\n",
    "\n",
    "        try:\n",
    "            matches = re.findall(r'\\d+', nearby_list_lines[-1])\n",
    "        except:\n",
    "            print(nearby_list)\n",
    "            sys.exit()\n",
    "        \n",
    "        id_list = [int(match) for match in matches]\n",
    "\n",
    "        if (id_list):\n",
    "            if (id_list[0] == 0):\n",
    "                id_list = []\n",
    "                print(f\"WARNING: No IDs identified at tick {tick}\")\n",
    "        else:\n",
    "            id_list = []\n",
    "            print(f\"ERROR: ID list not included for tick {tick} from response:\")\n",
    "            print(nearby_list)\n",
    "            print(\"-----\")\n",
    "\n",
    "        #print(id_list)\n",
    "\n",
    "        with open(yaml_path_dir + tick + \".yaml\") as f:\n",
    "            yaml_data = yaml.safe_load(f)\n",
    "\n",
    "        vehicle_dict = yaml_data.get(\"vehicles\", {})\n",
    "        ego_x, ego_y = yaml_data[\"true_ego_pos\"][:2]\n",
    "        ego_x = -ego_x\n",
    "        ego_yaw = -np.deg2rad(yaml_data[\"true_ego_pos\"][4])\n",
    "        ego_speed = yaml_data[\"ego_speed\"]\n",
    "        helper_x, helper_y = yaml_data[\"true_helper_pos\"][:2]\n",
    "        helper_x = -helper_x\n",
    "        helper_yaw = -np.deg2rad(yaml_data[\"true_helper_pos\"][4])\n",
    "        helper_speed = yaml_data[\"helper_speed\"]\n",
    "\n",
    "        final_structure_str = \"\"\n",
    "\n",
    "        #if (SCENE_TO_USE in [4, 4.5]):\n",
    "        ego_facing = directions_global[int((ego_yaw + math.pi/16)/(math.pi/8)) % 16]\n",
    "        final_structure_str += f\"Ego Vehicle: Facing {ego_facing}, Speed: {ego_speed}\\n\"\n",
    "\n",
    "        for id in id_list:\n",
    "            if (SCENE_TO_USE in [6, 7, 8, 9]) and (int(id) in [1, 2]):\n",
    "                strid = str(id).zfill(3)\n",
    "            else:\n",
    "                strid = str(id)\n",
    "            \n",
    "            if (strid in vehicle_dict):\n",
    "                info = vehicle_dict[strid]\n",
    "                other_x, other_y = info[\"location\"][:2]\n",
    "                other_x = -other_x\n",
    "                other_yaw = -np.deg2rad(info[\"angle\"][1])\n",
    "                rel_dir, distance_val, distance, facing = describe_relative_direction(ego_x, ego_y, ego_yaw, other_x, other_y, other_yaw)\n",
    "                speed_num = info[\"speed\"]\n",
    "                confidence_num = 0.0\n",
    "                try:\n",
    "                    confidence_num = info['confidence']\n",
    "                except:\n",
    "                    confidence_num = 0.0\n",
    "                    print(f\"WARNING: confidence_num missing for {id} at tick {tick}\")\n",
    "                if (speed_num < 1):\n",
    "                    speed = \"stopped\"\n",
    "                elif (speed_num < 5): # arbitrary - find a better way to do this later?\n",
    "                    speed = \"slow\"\n",
    "                else:\n",
    "                    speed = \"fast\"\n",
    "\n",
    "                if (confidence_num > 0.5):\n",
    "\n",
    "                    # check for possible imminent collision\n",
    "                    # assume ego speed = other car's speed\n",
    "                    speed_num *= -1\n",
    "\n",
    "                    # ego: ego_x, ego_y, ego_yaw, speed_num\n",
    "                    # other: other_x, other_y, other_yaw, speed_num\n",
    "                    # 1s threshold\n",
    "\n",
    "                    A= np.array([\n",
    "                        [speed_num*np.cos(other_yaw),-speed_num*np.cos(ego_yaw)],\n",
    "                        [speed_num*np.sin(other_yaw),-speed_num*np.sin(ego_yaw)]\n",
    "                    ])\n",
    "                    b=np.array([ego_x-other_x,ego_y-other_y])\n",
    "                    try:\n",
    "                        t=np.linalg.solve(A,b)\n",
    "                        t2=t[1]\n",
    "                        t1=t[0]\n",
    "                        final_structure_str += f\"Vehicle {id} (perception confidence {confidence_num:.2f}): Relative direction to Ego CAV: {rel_dir}, Distance: {distance_val} ({distance}), Facing {facing}, Speed: {speed}\"\n",
    "                        if (SCENE_TO_USE == 2):\n",
    "                            if((other_x > 35) and (other_x < 66) and (other_y < 30) and (other_y > 4)):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in the intersection\"\n",
    "                        if (SCENE_TO_USE == 3):\n",
    "                            if((other_x > -262) and (other_x < -250) and (other_y < -240) and (other_y > -258)):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in the intersection\"\n",
    "                        if (SCENE_TO_USE in [4, 4.5]):\n",
    "                            if (abs(other_y - ego_y) < 4 and abs(other_y - ego_y) > 3):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in an adjacent lane\"\n",
    "                        if (SCENE_TO_USE == 5):\n",
    "                            if ((other_x < 205) and (other_x > 180) and (other_y > 75) and (other_y < 104)):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in the intersection\"\n",
    "                        if(abs(t2-t1)<0.5 and t1>0 and t2>0 and ((t1+t2)/2 < 0.5)):\n",
    "                            final_structure_str += f\" - WARNING: Collision with this car potentially imminent\"\n",
    "                            print(\"*\", end=\" \")\n",
    "                        final_structure_str += \"\\n\"\n",
    "                    except np.linalg.LinAlgError:\n",
    "                        final_structure_str += f\"Vehicle {id} (perception confidence {confidence_num:.2f}): Relative direction to Ego CAV: {rel_dir}, Distance: {distance_val} ({distance}), Facing {facing}, Speed: {speed}\\n\"\n",
    "                        print(\"WARNING: LinAlgError\")\n",
    "                        print(A)\n",
    "                        print(b)\n",
    "            elif (strid == str(helper_cav_id)):\n",
    "                other_x = helper_x\n",
    "                other_y = helper_y\n",
    "                other_yaw = helper_yaw\n",
    "                rel_dir, distance_val, distance, facing = describe_relative_direction(ego_x, ego_y, ego_yaw, other_x, other_y, other_yaw)\n",
    "                speed_num = helper_speed\n",
    "                confidence_num = 1.0 # helper can guarantee its own presence\n",
    "                \n",
    "                if (speed_num < 1):\n",
    "                    speed = \"stopped\"\n",
    "                elif (speed_num < 5): # arbitrary - find a better way to do this later?\n",
    "                    speed = \"slow\"\n",
    "                else:\n",
    "                    speed = \"fast\"\n",
    "\n",
    "                if (confidence_num > 0.5):\n",
    "\n",
    "                    # check for possible imminent collision\n",
    "                    # assume ego speed = other car's speed\n",
    "                    speed_num *= -1\n",
    "\n",
    "                    # ego: ego_x, ego_y, ego_yaw, speed_num\n",
    "                    # other: other_x, other_y, other_yaw, speed_num\n",
    "                    # 1s threshold\n",
    "\n",
    "                    A= np.array([\n",
    "                        [speed_num*np.cos(other_yaw),-speed_num*np.cos(ego_yaw)],\n",
    "                        [speed_num*np.sin(other_yaw),-speed_num*np.sin(ego_yaw)]\n",
    "                    ])\n",
    "                    b=np.array([ego_x-other_x,ego_y-other_y])\n",
    "                    try:\n",
    "                        t=np.linalg.solve(A,b)\n",
    "                        t2=t[1]\n",
    "                        t1=t[0]\n",
    "                        final_structure_str += f\"Vehicle {id} (perception confidence {confidence_num:.2f}): Relative direction to Ego CAV: {rel_dir}, Distance: {distance_val} ({distance}), Facing {facing}, Speed: {speed}\"\n",
    "                        if (SCENE_TO_USE == 2):\n",
    "                            if((other_x > 35) and (other_x < 66) and (other_y < 30) and (other_y > 4)):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in the intersection\"\n",
    "                        if (SCENE_TO_USE == 3):\n",
    "                            if((other_x > -262) and (other_x < -250) and (other_y < -240) and (other_y > -258)):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in the intersection\"\n",
    "                        if (SCENE_TO_USE in [4, 4.5]):\n",
    "                            if (abs(other_y - ego_y) < 4 and abs(other_y - ego_y) > 3):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in an adjacent lane\"\n",
    "                        if (SCENE_TO_USE == 5):\n",
    "                            if ((other_x < 205) and (other_x > 180) and (other_y > 75) and (other_y < 104)):\n",
    "                                final_structure_str += f\" - NOTE: This vehicle is in the intersection\"\n",
    "                        if(abs(t2-t1)<0.5 and t1>0 and t2>0 and ((t1+t2)/2 < 0.5)):\n",
    "                            final_structure_str += f\" - WARNING: Collision with this car potentially imminent\"\n",
    "                            print(\"*\", end=\" \")\n",
    "                        final_structure_str += \"\\n\"\n",
    "                    except np.linalg.LinAlgError:\n",
    "                        final_structure_str += f\"Vehicle {id} (perception confidence {confidence_num:.2f}): Relative direction to Ego CAV: {rel_dir}, Distance: {distance_val} ({distance}), Facing {facing}, Speed: {speed}\\n\"\n",
    "                        print(\"WARNING: LinAlgError\")\n",
    "                        print(A)\n",
    "                        print(b)\n",
    "            else:\n",
    "                final_structure_str += f\"Vehicle {id}: Not found\\n\"\n",
    "                print(f\"ERROR: {id} identified but not found at tick {tick}\")\n",
    "\n",
    "        with open(out_dir + tick + \".txt\", \"w\") as outfile:\n",
    "            outfile.write(final_structure_str)\n",
    "\n",
    "        print(f\"Done with {tick}\")\n",
    "\n",
    "    average_time_taken = all_times_taken_sum / float(all_times_taken_num)\n",
    "\n",
    "    print(f\">> AVERAGE TIME TAKEN FOR {SCENE_TO_USE}: {average_time_taken}\")\n",
    "\n",
    "    print(f\">>> ALL DONE WITH {SCENE_TO_USE}\")\n",
    "\n",
    "print(\"FINISHED WITH EVERYTHING!! :D\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
